{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting diabetes \n",
    "This notebook uses the toolkit to develop a range of models for the diabetes use case using the Pima Indians dataset. Source: UCI repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import morpher\n",
    "from morpher.jobs import *\n",
    "from morpher.plots import *\n",
    "from morpher.metrics import *\n",
    "from morpher.config import (\n",
    "    imputers,\n",
    "    algorithms,\n",
    "    explainers\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic definitions\n",
    "Now define the set up for this classification problem, such as filename, target, and test size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"diabetes.csv\"\n",
    "target = \"diabetes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and imputing data \n",
    "Load the data set and impute it using the mean imputer and split it. Dataset should be composed of numeric or boolean features and target variable should be numeric, e.g., 0 for 'no' and 1 for 'yes'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Load().execute(filename=filename)\n",
    "data,_ = Impute().execute(data)\n",
    "\n",
    "train, test = Split().execute(\n",
    "    data, test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training different models\n",
    "Now train models using decision tree, random forest, gradient boosting decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "models = Train().execute(\n",
    "    train,\n",
    "    target=target,\n",
    "    algorithms=[ algorithms.DT, algorithms.RF, algorithms.GBDT ],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the models\n",
    "Now evaluate the trained models on the test set obtained previously and plot a ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = Evaluate().execute(test, target=target, models=models)\n",
    "plot_roc(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain the models\n",
    "Now explain the models using model feature contribution, LIME and mimic learning and plot the explanations for Random Forest (RF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations = Explain().execute(\n",
    "    data,\n",
    "    models=models,\n",
    "    explainers = [explainers.FEAT_CONTRIB, explainers.LIME, explainers.MIMIC],\n",
    "    target=target,\n",
    "    exp_args = {'test':test}                 \n",
    ")\n",
    "\n",
    "plot_explanation_heatmap(explanations[algorithms.RF])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
