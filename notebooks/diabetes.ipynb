{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting diabetes \n",
    "This notebook uses the toolkit to develop a range of models for the diabetes use case using the Pima Indians dataset. Source: UCI repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import morpher\n",
    "from morpher.jobs import *\n",
    "from morpher.plots import *\n",
    "from morpher.metrics import *\n",
    "from morpher.config import (\n",
    "    imputers,\n",
    "    algorithms,\n",
    "    explainers,\n",
    "    selectors,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic definitions\n",
    "Now define the set up for this classification problem, such as filename, target, and test size. Note that the input dataset must be numeric and the target variable binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'diabetes.csv'\n",
    "target = 'diabetes'\n",
    "test_size = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and imputing data \n",
    "Load the data set and impute it using the mean imputer and split it. Dataset should be composed of numeric or boolean features and target variable should be numeric, e.g., 0 for 'no' and 1 for 'yes'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Load().execute(filename=filename)\n",
    "data = data.drop('patient id', axis=1) #remove ids\n",
    "\n",
    "data,_ = Impute().execute(data)\n",
    "\n",
    "train, test = Split().execute(\n",
    "    data, test_size=test_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select best features\n",
    "Check what the most relevant features are using F-Test. `selection_method` can take any of the available methods in the toolkit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, selected_features = Select().execute(\n",
    "    train,\n",
    "    selection_method=selectors.F_TEST,\n",
    "    top=3,\n",
    "    target=target\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training different models\n",
    "Now train models using decision tree, random forest, gradient boosting decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "models = Train().execute(\n",
    "    train,\n",
    "    target=target,\n",
    "    algorithms=[algorithms.DT, algorithms.RF, algorithms.GBDT],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the models\n",
    "Now evaluate the trained models on the test set obtained previously and plot a ROC curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[selected_features + [target]] #get features selected + target\n",
    "results = Evaluate().execute(\n",
    "    test,\n",
    "    target=target,\n",
    "    models=models\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discrimination and clinical usefulness (decision curve)\n",
    "Use the curves below to identify how well the model is performing and whether it is clinical useful in a given threshold range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
    "\n",
    "''' Area under the curve '''\n",
    "plot_roc(results, ax=axs[0])\n",
    "\n",
    "''' Decision curve '''\n",
    "plot_dc(results, ax=axs[1])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain the models\n",
    "Now explain the models using model feature contribution, LIME and mimic learning and plot the explanations for Random Forest (RF)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "explanations = Explain().execute(\n",
    "    train,\n",
    "    models=models,\n",
    "    explainers = [explainers.FEAT_CONTRIB, explainers.LIME, explainers.MIMIC],\n",
    "    target=target,\n",
    "    exp_args = {'test':test}                 \n",
    ")\n",
    "\n",
    "plot_explanation_heatmap(explanations[algorithms.RF])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
